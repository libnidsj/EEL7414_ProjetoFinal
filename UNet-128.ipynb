{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwDHkJeRc1En"
   },
   "source": [
    "# 1. Download e tratamento do DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYNwok5fdBzz"
   },
   "source": [
    "## 1.1. Download dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbgg-N6bUa77",
    "outputId": "f2400350-be62-49bd-cc50-2dd516f1c8a6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14mwuIXjdF5L"
   },
   "source": [
    "# 2. Carregamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos dos diretórios\n",
    "train_watermarked_path = 'CLWD/train/Watermarked_image'\n",
    "train_non_watermarked_path = 'CLWD/train/Watermark_free_image'\n",
    "test_watermarked_path = 'CLWD/test/Watermarked_image'\n",
    "test_non_watermarked_path = 'CLWD/test/Watermark_free_image'\n",
    "results_filename = 'simple_unet'\n",
    "\n",
    "# Parâmetros\n",
    "batch_size = 32\n",
    "validation_split = 0.2\n",
    "img_dim = 128\n",
    "img_size = (img_dim, img_dim)\n",
    "steps_per_epoch = (1 - validation_split) * len(os.listdir(train_watermarked_path)) // batch_size\n",
    "validation_steps = validation_split * len(os.listdir(train_watermarked_path)) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(watermarked_path, non_watermarked_path, img_size, batch_size, validation_split=0.2, subset=None, shuffle=True):\n",
    "    # Lista de arquivos\n",
    "    watermarked_files = sorted([os.path.join(watermarked_path, f) for f in os.listdir(watermarked_path)])\n",
    "    non_watermarked_files = sorted([os.path.join(non_watermarked_path, f) for f in os.listdir(non_watermarked_path)])\n",
    "\n",
    "    # Certifique-se de que os arquivos correspondem em ordem\n",
    "    assert len(watermarked_files) == len(non_watermarked_files), \"Os conjuntos de dados devem ter o mesmo tamanho.\"\n",
    "    \n",
    "    # Determinar índice de divisão\n",
    "    split_index = int(len(watermarked_files) * (1 - validation_split))\n",
    "\n",
    "    if subset == \"training\":\n",
    "        watermarked_files = watermarked_files[:split_index]\n",
    "        non_watermarked_files = non_watermarked_files[:split_index]\n",
    "    elif subset == \"validation\":\n",
    "        watermarked_files = watermarked_files[split_index:]\n",
    "        non_watermarked_files = non_watermarked_files[split_index:]\n",
    "\n",
    "    # Criar dataset com pares de caminhos\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((watermarked_files, non_watermarked_files))\n",
    "\n",
    "    # Função para carregar e pré-processar as imagens\n",
    "    def preprocess(w_file, nw_file):\n",
    "        w_img = tf.io.read_file(w_file)\n",
    "        w_img = tf.image.decode_jpeg(w_img, channels=3)\n",
    "        w_img = tf.image.resize(w_img, img_size) / 255.0\n",
    "\n",
    "        nw_img = tf.io.read_file(nw_file)\n",
    "        nw_img = tf.image.decode_jpeg(nw_img, channels=3)\n",
    "        nw_img = tf.image.resize(nw_img, img_size) / 255.0\n",
    "\n",
    "        return w_img, nw_img\n",
    "\n",
    "    # Aplicar pré-processamento\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Embaralhar se necessário\n",
    "    if shuffle and subset == \"training\":\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "\n",
    "    # Dividir em lotes e aplicar prefetch\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MEa4-IAfmE9"
   },
   "source": [
    "# 3. Construção da UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "EWmEWzM5fpGD",
    "outputId": "3f6fab74-86cd-49d9-90f6-d00a0c78544b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 128, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, 128, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 64  36928       ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128, 128, 64  256        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 64, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 128)  73856       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 128)  147584      ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0          ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 256)  590080      ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0          ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 512)  2048       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 512)  2359808     ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 512)  2048       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 512)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 8, 1024)   4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 8, 8, 1024)  4096        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 1024)   9438208     ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 8, 1024)  4096        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 16, 16, 1024  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 512)  2097664     ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16, 16, 1024  0           ['conv2d_10[0][0]',              \n",
      "                                )                                 'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 512)  2359808     ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 512)  0          ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 256)  524544      ['up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 32, 32, 512)  0           ['conv2d_13[0][0]',              \n",
      "                                                                  'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 32, 32, 256)  1179904     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 32, 32, 256)  590080      ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 256)  0          ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 64, 64, 128)  131200      ['up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 64, 64, 256)  0           ['conv2d_16[0][0]',              \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 64, 64, 128)  295040      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 64, 64, 128)  512        ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 64, 64, 128)  147584      ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 64, 64, 128)  512        ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 12  0          ['batch_normalization_15[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 128, 128, 64  32832       ['up_sampling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 128, 12  0           ['conv2d_19[0][0]',              \n",
      "                                8)                                'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 128, 128, 64  73792       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 128, 128, 64  256        ['conv2d_20[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 128, 128, 64  36928       ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 128, 128, 64  256        ['conv2d_21[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 128, 128, 3)  195         ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,055,427\n",
      "Trainable params: 31,043,651\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import gc\n",
    "\n",
    "def build_unet(input_shape=(img_dim, img_dim, 3)):\n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder: Down-sampling\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "\n",
    "    # Decoder: Up-sampling\n",
    "    u6 = UpSampling2D((2, 2))(c5)\n",
    "    u6 = Conv2D(512, (2, 2), activation='relu', padding='same')(u6)\n",
    "    u6 = Concatenate()([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "\n",
    "    u7 = UpSampling2D((2, 2))(c6)\n",
    "    u7 = Conv2D(256, (2, 2), activation='relu', padding='same')(u7)\n",
    "    u7 = Concatenate()([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "\n",
    "    u8 = UpSampling2D((2, 2))(c7)\n",
    "    u8 = Conv2D(128, (2, 2), activation='relu', padding='same')(u8)\n",
    "    u8 = Concatenate()([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "\n",
    "    u9 = UpSampling2D((2, 2))(c8)\n",
    "    u9 = Conv2D(64, (2, 2), activation='relu', padding='same')(u9)\n",
    "    u9 = Concatenate()([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Conv2D(3, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    # Define the model\n",
    "    unet_model = Model(input_img, outputs)\n",
    "    return unet_model\n",
    "\n",
    "# Instanciar o modelo\n",
    "unet = build_unet()\n",
    "unet.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Adicionar callbacks\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=4,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='best_un_model.h5',  # Salva o melhor modelo\n",
    "        monitor='val_loss',  # Monitora a perda de validação\n",
    "        save_best_only=True, # Salva apenas se for o melhor modelo\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "unet.summary()\n",
    "\n",
    "# Liberação de memória\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C310aGfQfrAX"
   },
   "source": [
    "# 4. Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EBcZ5Pz2ft-z",
    "outputId": "13315fa9-dd10-45f1-810e-cb695d24a40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00302, saving model to best_un_model.h5\n",
      "1500/1500 [==============================] - 539s 353ms/step - loss: 0.0040 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00302\n",
      "1500/1500 [==============================] - 534s 355ms/step - loss: 0.0032 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00302\n",
      "1500/1500 [==============================] - 533s 355ms/step - loss: 0.0028 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00302\n",
      "1500/1500 [==============================] - 532s 355ms/step - loss: 0.0025 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 5: val_loss improved from 0.00302 to 0.00172, saving model to best_un_model.h5\n",
      "1500/1500 [==============================] - 534s 356ms/step - loss: 0.0020 - val_loss: 0.0017 - lr: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 6: val_loss improved from 0.00172 to 0.00143, saving model to best_un_model.h5\n",
      "1500/1500 [==============================] - 534s 356ms/step - loss: 0.0017 - val_loss: 0.0014 - lr: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 7: val_loss improved from 0.00143 to 0.00137, saving model to best_un_model.h5\n",
      "1500/1500 [==============================] - 534s 356ms/step - loss: 0.0015 - val_loss: 0.0014 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00137\n",
      "1500/1500 [==============================] - 533s 355ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 9: val_loss improved from 0.00137 to 0.00135, saving model to best_un_model.h5\n",
      "1500/1500 [==============================] - 553s 368ms/step - loss: 0.0013 - val_loss: 0.0014 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 10: val_loss improved from 0.00135 to 0.00103, saving model to best_un_model.h5\n",
      "1500/1500 [==============================] - 591s 393ms/step - loss: 0.0011 - val_loss: 0.0010 - lr: 2.5000e-04\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 11: val_loss improved from 0.00103 to 0.00099, saving model to best_un_model.h5\n",
      "1500/1500 [==============================] - 613s 408ms/step - loss: 0.0010 - val_loss: 9.8701e-04 - lr: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1423/1500 [===========================>..] - ETA: 27s - loss: 9.9850e-04  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m create_dataset(\n\u001b[0;32m      7\u001b[0m     train_watermarked_path, train_non_watermarked_path, \n\u001b[0;32m      8\u001b[0m     img_size, batch_size, validation_split\u001b[38;5;241m=\u001b[39mvalidation_split, subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/device:GPU:0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Treinamento\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43munet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset = create_dataset(\n",
    "    train_watermarked_path, train_non_watermarked_path, \n",
    "    img_size, batch_size, validation_split=validation_split, subset=\"training\"\n",
    ")\n",
    "\n",
    "val_dataset = create_dataset(\n",
    "    train_watermarked_path, train_non_watermarked_path, \n",
    "    img_size, batch_size, validation_split=validation_split, subset=\"validation\"\n",
    ")\n",
    "\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    # Treinamento\n",
    "    history = unet.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_dataset,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=callbacks,\n",
    "        epochs=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0WV74iHfyHN"
   },
   "source": [
    "# 5. Avaliação e visualização dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8akkPO-1nS1o"
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history, output_dir=\"output\", file_name=\"train_history.png\"):\n",
    "\n",
    "    # Cria o diretório de saída, se necessário\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Caminho completo para salvar o arquivo\n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Treinamento', color='blue', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validação', color='orange', linewidth=2)\n",
    "    plt.title('Perda Durante o Treinamento e Validação', fontsize=16)\n",
    "    plt.xlabel('Épocas', fontsize=14)\n",
    "    plt.ylabel('Perda', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)  # Salva o plot no arquivo\n",
    "    print(f\"Imagens salvas em: {output_path}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Chamando a função após o treinamento\n",
    "plot_training_history(history, output_dir=\"results\", file_name=results_filename+'_training.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path, img_size):\n",
    "    \"\"\"\n",
    "    Carrega uma imagem a partir do caminho e redimensiona.\n",
    "    \"\"\"\n",
    "    image = tf.keras.utils.load_img(file_path, target_size=img_size)\n",
    "    image = tf.keras.utils.img_to_array(image) / 255.0  # Normaliza para [0, 1]\n",
    "    return image\n",
    "\n",
    "\n",
    "def create_test_dataset(watermarked_path, non_watermarked_path, img_size, batch_size):\n",
    "    \"\"\"\n",
    "    Cria o dataset de teste com pares de imagens (com e sem marca d'água).\n",
    "    \"\"\"\n",
    "    # Lista arquivos nos diretórios\n",
    "    watermarked_files = sorted(os.listdir(watermarked_path), key=lambda x: int(x.split('.')[0]))\n",
    "    non_watermarked_files = sorted(os.listdir(non_watermarked_path), key=lambda x: int(x.split('.')[0]))\n",
    "    \n",
    "    # Verifica se os dois conjuntos possuem o mesmo número de arquivos\n",
    "    assert len(watermarked_files) == len(non_watermarked_files), \\\n",
    "        \"O número de arquivos nos dois diretórios deve ser o mesmo.\"\n",
    "\n",
    "    # Carrega as imagens\n",
    "    watermarked_images = [\n",
    "        load_image(os.path.join(watermarked_path, file), img_size) for file in watermarked_files\n",
    "    ]\n",
    "    non_watermarked_images = [\n",
    "        load_image(os.path.join(non_watermarked_path, file), img_size) for file in non_watermarked_files\n",
    "    ]\n",
    "\n",
    "    # Combina em pares\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((watermarked_images, non_watermarked_images))\n",
    "    dataset = dataset.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "test_dataset = create_test_dataset(\n",
    "    test_watermarked_path, test_non_watermarked_path, img_size, batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_metrics(model, dataset, max_pixel_value=1.0):\n",
    "\n",
    "    rmse_values = []\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "\n",
    "    with tf.device(\"/device:GPU:0\"):\n",
    "\n",
    "        for watermarked, non_watermarked in dataset:\n",
    "            # Previsão pelo modelo\n",
    "            reconstructed = model.predict(watermarked, verbose=0)\n",
    "    \n",
    "            # Converte para arrays NumPy, se necessário\n",
    "            y_true = non_watermarked.numpy() if hasattr(non_watermarked, 'numpy') else np.array(non_watermarked)\n",
    "            y_pred = reconstructed\n",
    "    \n",
    "            # Normaliza as imagens, se necessário\n",
    "            y_true = np.clip(y_true, 0, max_pixel_value)\n",
    "            y_pred = np.clip(y_pred, 0, max_pixel_value)\n",
    "    \n",
    "            # Calcula RMSE\n",
    "            mse = mean_squared_error(y_true.flatten(), y_pred.flatten())\n",
    "            rmse = np.sqrt(mse)\n",
    "            rmse_values.append(rmse)\n",
    "    \n",
    "            # Calcula PSNR\n",
    "            psnr = 20 * np.log10(max_pixel_value / np.sqrt(mse)) if mse > 0 else float('inf')\n",
    "            psnr_values.append(psnr)\n",
    "    \n",
    "            # Calcula SSIM\n",
    "            ssim_value = ssim(y_true, y_pred, data_range=max_pixel_value, multichannel=True, channel_axis=-1)\n",
    "            ssim_values.append(ssim_value)\n",
    "\n",
    "    # Calcula as médias de cada métrica\n",
    "    metrics = {\n",
    "        \"RMSE\": np.mean(rmse_values),\n",
    "        \"PSNR\": np.mean(psnr_values),\n",
    "        \"SSIM\": np.mean(ssim_values)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Calcula RMSE no conjunto de treinamento\n",
    "train_metrics = evaluate_model_metrics(unet, train_dataset)\n",
    "print(\"Métricas médias do treinamento:\")\n",
    "print(f\"RMSE: {train_metrics['RMSE']:.4f}\")\n",
    "print(f\"PSNR: {train_metrics['PSNR']:.2f} dB\")\n",
    "print(f\"SSIM: {train_metrics['SSIM']:.4f}\")\n",
    "\n",
    "# Calcula RMSE no conjunto de validacao\n",
    "val_metrics = evaluate_model_metrics(unet, val_dataset)\n",
    "print(\"Métricas médias da validacao:\")\n",
    "print(f\"RMSE: {val_metrics['RMSE']:.4f}\")\n",
    "print(f\"PSNR: {val_metrics['PSNR']:.2f} dB\")\n",
    "print(f\"SSIM: {val_metrics['SSIM']:.4f}\")\n",
    "\n",
    "# Calcula o RMSE no conjunto de teste\n",
    "test_metrics = evaluate_model_metrics(unet, test_dataset)\n",
    "print(\"Métricas médias do teste:\")\n",
    "print(f\"RMSE: {test_metrics['RMSE']:.4f}\")\n",
    "print(f\"PSNR: {test_metrics['PSNR']:.2f} dB\")\n",
    "print(f\"SSIM: {test_metrics['SSIM']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_show_reconstructed_images(model, test_dataset, num_images=15, output_dir=\"output\", file_name=\"reconstructed_images.png\"):\n",
    "\n",
    "    # Cria o diretório de saída, se necessário\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Caminho completo para salvar o arquivo\n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    \n",
    "    # Obtém um lote de imagens do dataset de teste\n",
    "    for watermarked, non_watermarked in test_dataset.take(1):\n",
    "        # Previsão do modelo\n",
    "        reconstructed = model.predict(watermarked, verbose=0)\n",
    "\n",
    "        # Número de imagens a serem plotadas\n",
    "        num_images = min(num_images, watermarked.shape[0])\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        for i in range(num_images):\n",
    "            # Imagem com marca d'água\n",
    "            ax = plt.subplot(3, num_images, i + 1)\n",
    "            plt.imshow(watermarked[i])\n",
    "            if i == 0:\n",
    "                plt.title(\"Com marca d'água\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            # Imagem original\n",
    "            ax = plt.subplot(3, num_images, i + 1 + num_images)\n",
    "            plt.imshow(non_watermarked[i])\n",
    "            if i == 0:\n",
    "                plt.title(\"Original\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            # Imagem reconstruída\n",
    "            ax = plt.subplot(3, num_images, i + 1 + 2 * num_images)\n",
    "            plt.imshow(reconstructed[i])\n",
    "            if i == 0:\n",
    "                plt.title(\"Reconstruída\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path)  # Salva o plot no arquivo\n",
    "        print(f\"Imagens salvas em: {output_path}\")\n",
    "        plt.show()  # Exibe a figura na tela\n",
    "        plt.close()  # Fecha a figura para liberar memória\n",
    "        break  # Apenas um lote é necessário\n",
    "\n",
    "# Plota 15 imagens do conjunto de teste\n",
    "save_and_show_reconstructed_images(unet, test_dataset, num_images=15, output_dir=\"results\", file_name=results_filename+'_images.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPF03XWMf2bZ"
   },
   "source": [
    "# 6. Salvar o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OT2SbXtRf4no"
   },
   "outputs": [],
   "source": [
    "# Salvar o modelo treinado\n",
    "unet.save('models/'+results_filename+'.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
